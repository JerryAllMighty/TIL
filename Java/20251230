[서두]
- JIT 컴파일러 관련 딥다이브가 내용이 좋아 공유하려한다.

[내용]
# JIT 컴파일러

## 나오게 된 계기
순수 인터프리터 방식은 같은 코드를 실행할 때마다 계속 해석해야 해서, 네이티브로 미리 컴파일된 코드보다 훨씬 느리다

## 정적 컴파일 vs 인터프리트의 트레이드오프 문제
미리 전부 컴파일(AOT)하면 실행 속도는 빠르지만, 시작 시점에 컴파일 시간이 길고
런타임 정보(실제 분기·프로파일)를 모른 상태라 최적화에 한계가 있다.
반대로 인터프리트는 시작은 빠르지만, 전체 실행 내내 느린 속도로 수행된다.
JIT는 “처음엔 인터프리터처럼 빠르게 시작하고, 실행하면서 모은 프로파일로 최적화를 점점 적용”해서 둘의 장점을 섞는다.

## 플랫폼 독립성과 성능을 동시에 만족시키려는 요구
자바처럼 .class 바이트코드 한 번만 만들어 두고 여러 아키텍처(JVM이 있는 곳 어디든)에서 돌리려면, 런타임에 각 플랫폼용 기계어로 바꾸는 과정이 필요하다.

JIT는 이 바이트코드를 “실행 중에 해당 플랫폼용 네이티브 코드로 번역”하고, 자주 호출되는 메서드만 골라 강하게 최적화해서, 바이트코드·가상머신 모델의 이식성과 네이티브에 가까운 속도를 동시에 노린다

## 실제 실행 패턴 기반의 동적 최적화 필요
정적 컴파일은 소스만 보고 추측해서 최적화하지만, 어떤 메서드가 진짜로 많이 호출되는지, 어떤 분기가 실제로 자주 타지는지는 런타임에만 정확히 알 수 있다.

JIT는 프로파일링 정보(호출 횟수, 분기 빈도 등)를 보고 핫스팟 메서드를 인라이닝, 루프 최적화, 탈가상화 등으로 재컴파일해서, 정적 컴파일만으로는 얻기 어려운 수준의 최적화를 가능하게 한다

## JIT 컴파일러의 최적화 전략
다른 글을 참고하면 좋다.
https://velog.io/@dbsalszz/%EC%9E%90%EB%B0%94-%EB%94%A5%EB%8B%A4%EC%9D%B4%EB%B8%8C-JIT-%EC%BB%B4%ED%8C%8C%EC%9D%BC%EB%9F%AC%EC%99%80-%EC%9B%9C%EC%97%85warm-up-%EA%B3%BC%EC%A0%95

# JIT 컴파일러의 힙 메모리 사용량 증가가 시스템에 미치는 영향과 튜닝 방법은?
## GC 부담, 응답 지연 증가
JIT 최적화로 더 많은 객체가 오래 살아남거나, 힙을 넉넉하게 잡아두면 GC가 더 드물지만 한 번에 오래 걸리는 방향으로 바뀌어, 레이턴시 민감한 서비스에서 STW 구간이 체감될 수 있다.

tiered compilation 등으로 더 많은 메서드를 컴파일하면 코드 캐시와 관련 메타/프로파일 데이터가 늘어나 전체 JVM 메모리 풋프린트가 커지고, 컨테이너나 작은 인스턴스에서는 메모리 압박으로 인한 OOM·스왑 위험이 증가한다.

## 코드 캐시(code cache) 포화로 인한 성능 저하
HotSpot의 코드 캐시는 JIT가 생성한 네이티브 코드를 저장하는 영역인데, 이게 꽉 차면 JIT가 더 이상 최적화 컴파일을 못 해서 인터프리트 비율이 올라가고, 이미 컴파일된 코드 일부를 지워야 하는 상황에서는 재컴파일·캐시 관리 오버헤드가 생긴다.

지나치게 큰 코드 캐시는 메모리 소모를 키우고, 지나치게 작은 코드 캐시는 “warm-up 이후 성능이 안 오르는” 형태로 나타나기 때문에 둘 사이의 밸런스가 중요하다.

## 컨테이너/제한 환경에서의 네이티브 메모리 문제
JIT는 힙 외에도 코드 캐시, 컴파일 버퍼, 내부 데이터 구조 등에 네이티브 메모리를 사용하므로, 컨테이너 메모리 제한에 근접한 환경에서는 힙은 여유 있어도 전체 프로세스 메모리 한도에 막혀 죽는 케이스가 보고된다.

이때는 -Xmx만 줄이는 게 아니라 코드 캐시 크기, 스레드 수, tiered compilation 사용 여부 등을 함께 조정해야 한다.
